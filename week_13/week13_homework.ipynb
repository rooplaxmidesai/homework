{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#import module for train and test split\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load cast dataset\n",
    "cast_df = pd.read_csv(\"cast.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cast dataset preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling null values - cast dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As most of the values in below mentioned columns are null, drop these columns\n",
    "cast_df.drop(['Data_Or','Order_Occ','Cruz_Leg','IntChl','IntC14','Inc_Str','Inc_End','PST_LAN',\n",
    "              'Civil_T','ForelU','Secchi','Cloud_Amt','Cloud_Typ','Wave_Prd','Wave_Ht','TimeZone',\n",
    "              'Wave_Dir','Wea','Barometer','Dry_T','Wet_T','Distance','Visibility','Bottom_D'],axis=1,inplace=True)\n",
    "\n",
    "#Fill null values \n",
    "cast_df.fillna({\"Wind_Spd\":0,\n",
    "                \"Wind_Dir\":cast_df[\"Wind_Dir\"].mean()},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning(dashes, odd characters etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast_df['Date'] = pd.to_datetime(cast_df[\"Date\"])\n",
    "cast_df['Month'] = cast_df[\"Date\"].dt.month\n",
    "cast_df['Day'] = cast_df[\"Date\"].dt.day\n",
    "cast_df['Year'] = cast_df[\"Date\"].dt.year\n",
    "\n",
    "cast_df.drop(['Date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert categorical values to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = LabelEncoder()\n",
    "#Label encode Ship_Name\n",
    "cast_df[\"Ship_Name\"] = cast_df[\"Ship_Name\"].astype(str)\n",
    "cast_df[\"Ship_Name\"] = class_labels.fit_transform(cast_df[\"Ship_Name\"].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2\n",
       "1         2\n",
       "2         2\n",
       "3         2\n",
       "4         2\n",
       "         ..\n",
       "34399    27\n",
       "34400    27\n",
       "34401    27\n",
       "34402    27\n",
       "34403    27\n",
       "Name: Ship_Name, Length: 34404, dtype: int32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cast_df[\"Ship_Name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encode- Cast dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Type_10</th>\n",
       "      <th>Data_Type_CT</th>\n",
       "      <th>Data_Type_HY</th>\n",
       "      <th>Data_Type_MX</th>\n",
       "      <th>Data_Type_PR</th>\n",
       "      <th>Sta_Code_IMX</th>\n",
       "      <th>Sta_Code_MBR</th>\n",
       "      <th>Sta_Code_NRO</th>\n",
       "      <th>Sta_Code_NST</th>\n",
       "      <th>Sta_Code_OCO</th>\n",
       "      <th>...</th>\n",
       "      <th>Ship_Code_32OC</th>\n",
       "      <th>Ship_Code_32QU</th>\n",
       "      <th>Ship_Code_32WC</th>\n",
       "      <th>Ship_Code_33DP</th>\n",
       "      <th>Ship_Code_33RL</th>\n",
       "      <th>Ship_Code_33RR</th>\n",
       "      <th>Ship_Code_33SR</th>\n",
       "      <th>Ship_Code_57VA</th>\n",
       "      <th>Ship_Code_90EK</th>\n",
       "      <th>Ship_Code_90PN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34399</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34400</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34401</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34402</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34403</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34404 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_Type_10  Data_Type_CT  Data_Type_HY  Data_Type_MX  Data_Type_PR  \\\n",
       "0                 0             0             1             0             0   \n",
       "1                 0             0             1             0             0   \n",
       "2                 0             0             1             0             0   \n",
       "3                 0             0             1             0             0   \n",
       "4                 0             0             1             0             0   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "34399             0             0             0             1             0   \n",
       "34400             0             0             0             1             0   \n",
       "34401             0             0             0             1             0   \n",
       "34402             0             0             0             1             0   \n",
       "34403             0             0             0             1             0   \n",
       "\n",
       "       Sta_Code_IMX  Sta_Code_MBR  Sta_Code_NRO  Sta_Code_NST  Sta_Code_OCO  \\\n",
       "0                 0             0             0             1             0   \n",
       "1                 0             0             0             1             0   \n",
       "2                 0             0             0             1             0   \n",
       "3                 0             0             0             1             0   \n",
       "4                 0             0             0             1             0   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "34399             0             0             0             0             0   \n",
       "34400             0             0             0             0             0   \n",
       "34401             0             0             0             0             0   \n",
       "34402             0             0             0             0             0   \n",
       "34403             0             0             0             0             0   \n",
       "\n",
       "       ...  Ship_Code_32OC  Ship_Code_32QU  Ship_Code_32WC  Ship_Code_33DP  \\\n",
       "0      ...               0               0               0               0   \n",
       "1      ...               0               0               0               0   \n",
       "2      ...               0               0               0               0   \n",
       "3      ...               0               0               0               0   \n",
       "4      ...               0               0               0               0   \n",
       "...    ...             ...             ...             ...             ...   \n",
       "34399  ...               0               0               0               0   \n",
       "34400  ...               0               0               0               0   \n",
       "34401  ...               0               0               0               0   \n",
       "34402  ...               0               0               0               0   \n",
       "34403  ...               0               0               0               0   \n",
       "\n",
       "       Ship_Code_33RL  Ship_Code_33RR  Ship_Code_33SR  Ship_Code_57VA  \\\n",
       "0                   0               0               0               0   \n",
       "1                   0               0               0               0   \n",
       "2                   0               0               0               0   \n",
       "3                   0               0               0               0   \n",
       "4                   0               0               0               0   \n",
       "...               ...             ...             ...             ...   \n",
       "34399               0               0               1               0   \n",
       "34400               0               0               1               0   \n",
       "34401               0               0               1               0   \n",
       "34402               0               0               1               0   \n",
       "34403               0               0               1               0   \n",
       "\n",
       "       Ship_Code_90EK  Ship_Code_90PN  \n",
       "0                   0               0  \n",
       "1                   0               0  \n",
       "2                   0               0  \n",
       "3                   0               0  \n",
       "4                   0               0  \n",
       "...               ...             ...  \n",
       "34399               0               0  \n",
       "34400               0               0  \n",
       "34401               0               0  \n",
       "34402               0               0  \n",
       "34403               0               0  \n",
       "\n",
       "[34404 rows x 45 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encode_df = pd.get_dummies(cast_df[['Data_Type','Sta_Code','Ship_Code']])\n",
    "onehot_encode_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle multicollinearity - cast dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cast_df = pd.concat([cast_df,onehot_encode_df],axis=1)\n",
    "#removing multicollinearity from one hot encoding\n",
    "cast_df.drop(['Data_Type','Data_Type_PR','Sta_Code','Sta_Code_SCO','Ship_Code','Ship_Code_90PN'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cast dataset - Heatmap\n",
    "corr() gives Pearson's correlation coefficient by default, which is linear correlation that measures the linear relationship between variables\n",
    "If the relationship between the two features is closer to some linear function, then their linear correlation is stronger and the absolute value of the correlation coefficient is higher.\n",
    "The color map that is used for below heatmap is 'RdBu', where dark shade of blue is postitive correlation and dark shade of red is negative correlation. Lighter shades of blue and red are very less or not correlated. Positive correlation is where if one value increases the other value increases too showing the linear correlation of line going up if we try to draw line between the scatter plot.\n",
    "\n",
    "* Positive correlation\n",
    "    - Correlation between the same feature is always strongly postitive which you see as all the diagonal values are 1\n",
    "    - Cst_Cnt and \n",
    "    - Cruise and Cst_Cnt has strong positive correlation of 0.98\n",
    "    - Cruz_Sta and Cst_Cnt has strong positive correlation of 0.98\n",
    "    - Year,Julian_Date and Cst_Cnt has strong positive correlation of 0.98\n",
    "    - Year and Cruise,Criz_Sta has strong positive correlation of 1\n",
    "    - Year and Cruise has strong positive correlation of 1\n",
    "    - Year and Cruz_Sta has strong positive correlation of 0.98\n",
    "    - Julian_Date and Cruise has strong positive correlation of 0.99\n",
    "    - Julian_Date and Cruz_Sta has strong positive correlation of 0.99\n",
    "    - Month and Julian_date has strong positive correlation of 0.97\n",
    "    - Rpt_Line,Ac_line and DbSta_ID has strong positive correlation of 1\n",
    "    - Lon_Dec, Lon_Deg and DbSta_ID has positive correlation greater than 0.80\n",
    "    - Ac_line and Rpt_Line has strong positive correlation of 1\n",
    "    - Lon_Dec and Lon_Deg has strong positive correlation of 1\n",
    "    - St_Station and Rpt_Sta has strong positive correlation of 1\n",
    "\n",
    "* Negative correlation\n",
    "    - DBSta_ID and Lat_Dec,Lat_Deg has negative correlation of -0.96\n",
    "    - Rpt_Line and Lat_Dec,Lat_Deg has negative correlation of -0.96\n",
    "    - Ac_Line and Lat_Dec,Lat_Deg has negative correlation of -0.96\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,20))\n",
    "sns.heatmap(cast_df.corr(),cmap=\"RdBu\",annot=True,linewidth=1,fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cast dataset -  removing highly correlated and redundant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing some of features that are highly correlated\n",
    "#Lat_Hem has value 'N' for all the records,\n",
    "#Lon_Hem has 'W' for all the records\n",
    "cast_df.drop(['Julian_Date','Julian_Day','Cst_Cnt','Cruise','Quarter',\n",
    "              'DbSta_ID','Lon_Dec','Ac_Line','St_Station','Lat_Hem','Lon_Hem'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottle dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load bottle dataset\n",
    "bottle_df = pd.read_csv(\"bottle.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get the column names where null value count is greater than 100000\n",
    "#There are 50 columns that match this criteria\n",
    "null_cnt_df = pd.DataFrame(bottle_df.isnull().sum())\n",
    "null_cnt_df.columns = ['Sum']\n",
    "null_cnt_df = null_cnt_df[null_cnt_df['Sum']>100000]\n",
    "null_cnt_df.T.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop those null value columns from above step\n",
    "bottle_df.drop(null_cnt_df.T.columns,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottle dataset heatmap\n",
    "corr() gives Pearson's correlation coefficient by default, which is linear correlation that measures the linear relationship between variables\n",
    "If the relationship between the two features is closer to some linear function, then their linear correlation is stronger and the absolute value of the correlation coefficient is higher.\n",
    "The color map that is used for below heatmap is 'RdBu', where dark shade of blue is postitive correlation and dark shade of red is negative correlation. Lighter shades of blue and red are very less or not correlated. Positive correlation is where if one value increases the other value increases too showing the linear correlation of line going up if we try to draw line between the scatter plot.\n",
    "\n",
    "* Positive correlation\n",
    "    - Correlation between the same feature is always strongly postitive which you see as all the diagonal values are 1\n",
    "    - Cst_Cnt and Bill_Cnt has positive correlation of 1\n",
    "    - R_Depth and Depthm has positive correlation of 1\n",
    "    - R_PRES and Depthm has positive correlation of 1\n",
    "    - T_DegC and R_Temp, R_POTEMP has positive correlation of 1\n",
    "    - T_DegC and R_SVA has positive correlation of 0.96\n",
    "    - R_Salinity and Salnty has positive correlation of 1\n",
    "    - R_SIGMA and STheta has positive correlation of 0.96\n",
    "    - C14A2q,DarkAq,MeanAq and C14A1q has strong positive correlation of 1\n",
    "\n",
    "* Negative correlation\n",
    "    - R_SVA and Depthm has negative correlation of -0.67\n",
    "    - R_Temp and Salnty has negative correaltion of -0.51\n",
    "    - STheta and T_DegC has negative correaltion of -0.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottle_df.head()\n",
    "plt.figure(figsize=(24,20))\n",
    "sns.heatmap(bottle_df.corr(),cmap=\"RdBu\",annot=True,linewidth=1,fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing columns that are highly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['Btl_Cnt','Depthm','R_TEMP','R_POTEMP','R_SALINITY','R_SIGMA','DarkAq','MeanAq']\n",
    "bottle_df.drop(cols_to_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill null values with mode\n",
    "bottle_df.fillna(value = {\"T_prec\":bottle_df[\"T_prec\"].mode()[0],\n",
    "                  \"S_prec\":bottle_df[\"S_prec\"].mode()[0],\n",
    "                  \"NH3q\":bottle_df[\"NH3q\"].mode()[0],\n",
    "                  \"C14A1q\":bottle_df[\"C14A1q\"].mode()[0],\n",
    "                  \"C14A2q\":bottle_df[\"C14A2q\"].mode()[0]},inplace=True)\n",
    "\n",
    "#Convert float data type to integer as values are all integer but stored as float\n",
    "bottle_df[['RecInd','T_prec','S_prec','NH3q','C14A1q','C14A2q','R_PRES']] = bottle_df[['RecInd','T_prec','S_prec','NH3q','C14A1q','C14A2q','R_PRES']].astype(int)\n",
    "\n",
    "print(bottle_df.isnull().sum())\n",
    "bottle_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing values in Temperature and Salinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp_salnty_df=bottle_df[['Salnty','T_degC']]\n",
    "temp_salnty_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_salnty_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_salnty_df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the null values of Salinity and temperature\n",
    "temp_salnty_df.dropna(thresh=2,inplace=True)\n",
    "temp_salnty_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take only 5000 records of Salinity and Temperature\n",
    "temp_salnty_df = temp_salnty_df[:][:5000]\n",
    "print(temp_salnty_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_salinity = temp_salnty_df[\"Salnty\"].values\n",
    "y_temp = temp_salnty_df[\"T_degC\"].values\n",
    "\n",
    "X_salinity= X_salinity.reshape(-1,1)\n",
    "#y_temp= y_temp.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,9))\n",
    "sns.scatterplot(x=temp_salnty_df[\"Salnty\"], y=temp_salnty_df[\"T_degC\"])\n",
    "plt.suptile(\"Temperature vs Salinity\")\n",
    "plt.xlabel(\"Salinity\")\n",
    "plt.ylabel(\"Temperature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 & 4. Perform linear regression, find mean squared error and R square values \n",
    "#### Mean Squared Error and R^2 values\n",
    "* Mean Squared Error - Is the average of the sqaures of the errors. The larger the number the larger the error. Error in this case means the difference between the observed values and predicted values.There is no correct answer for MSE but lower the value of MSE its better. Predicted values of temperature and acutal values of temperature MSE is as below:\n",
    "    - Mean Squared Error: 8.460170488311233\n",
    "\n",
    "* R Sqaure\n",
    "    - R^2: 0.4255818269267334 this is same as calculating accuracy. The predicted values are 42% accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regression splitting into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_size=0.3 implies that the test part of the data will be 30%\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_salinity, y_temp, test_size = 0.3, random_state = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_train,y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "#Accuracy\n",
    "print(\"Accuracy {}\".format(reg.score(X_test,y_test)))\n",
    "\n",
    "#R2 value for linear regression\n",
    "print(\"R^2: {}\".format(r2_score(y_test,y_pred)))\n",
    "\n",
    "#Mean Squared Error\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "print(\"Mean Squared Error: {}\".format(mse))\n",
    "\n",
    "#Root Mean Squared Error\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Relationship between water temp and salinity. Show trend line with predicted temperature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,9))\n",
    "plt.scatter(x=X_train, y=y_train)\n",
    "plt.plot(X_test,y_pred,color='black',linewidth=1)\n",
    "plt.suptitle('Temperature versus Salinity')\n",
    "plt.xlabel(\"Salinity\")\n",
    "plt.ylabel(\"Temperature\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Describe Polynomial Regression\n",
    "* Polynomial Regression\n",
    "    - If the data points doesn't clearly fit the linear regression i.e a straight line through data points, it may be ideal for polynomial regression\n",
    "    - Polynomial regression uses the relationship between the variables to find the best way to draw a line through data points\n",
    "    - Linear algorithms such as linear and logistics regression respond well to use of polynomial input feature. Adding polynomial feature can be an effective way of allowing the model to indentify non-linear pattern\n",
    "    - When using polynomial features in linear regression it is called Polynomial regression\n",
    "\n",
    "* Polynomial Features\n",
    "    - Polynomial features transforms by raising existing features to an exponent and create new version of input variables for predictive modeling\n",
    "    - Polynomial feature is a type of feature engineering where you create new input feature from existing one\n",
    "    - Adding polynomial features can result in improved performance\n",
    "\n",
    "* Degree of the polynomial\n",
    "    - Degree of polynomial impacts the number of features created by transform\n",
    "    - Typically a small degree 2 or 3 is used. It unusal to use higher degree as it can result in overfitting.\n",
    "    \n",
    "    \n",
    "* Please see below for example of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define sample dataset\n",
    "X_test_dataset = np.asarray([[2],[4],[5]])\n",
    "print(X_test_dataset)\n",
    "\n",
    "#perform a polynomial features transform of the dataset for degree ranging from 1 to 5\n",
    "degrees = [i for i in range(1,6)]\n",
    "for d in degrees:\n",
    "    poly_features = PolynomialFeatures(degree=d) \n",
    "    test_dataset = poly_features.fit_transform(X_test_dataset)\n",
    "    print('Degree:', d , 'Features:', test_dataset.shape)\n",
    "    print(test_dataset)\n",
    "\n",
    "# As the degree goes up, number of features dramatically goes up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,9))\n",
    "#using the train and test data created using train_test_split\n",
    "plt.scatter(X_train,y_train,color='blue')\n",
    "\n",
    "#Without using split \n",
    "#plt.scatter(X_salinity,y_temp,color='blue')\n",
    "plt.suptile(\"Temperature vs Salinity\")\n",
    "plt.xlabel(\"Salinity\")\n",
    "plt.ylabel(\"Temperature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg = PolynomialFeatures(degree=3)\n",
    "linreg = LinearRegression()\n",
    "\n",
    "#using the train and test data created using train_test_split\n",
    "#X_poly = poly_reg.fit_transform(X_train)\n",
    "#poly_reg.fit(X_poly,y_train)\n",
    "#linreg.fit(X_poly,y_train)\n",
    "\n",
    "#Without using split \n",
    "X_poly = poly_reg.fit_transform(X_salinity)\n",
    "poly_reg.fit(X_poly,y_temp)\n",
    "linreg.fit(X_poly,y_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_temp_poly = linreg.predict(poly_reg.fit_transform([[32.546]]))\n",
    "prediction_temp_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error and R^2 values\n",
    "* Mean Squared Error is the average of the sqaures of the errors. The larger the number the larger the error. Error in this case means the difference between the observed values and predicted values.There is no correct answer for MSE but lower the value of MSE its better. Predicted values of temperature and acutal values of temperature MSE is as below which is lower than the linear regression model.\n",
    "    - Mean Squared Error: R^2: 6.016453703873993\n",
    "\n",
    "* R Square\n",
    "    - R^2: 0.5995609258276697 which is same as accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#using the train and test data created using train_test_split\n",
    "#Accuracy\n",
    "print(\"R^2: {}\".format(linreg.score(poly_reg.fit_transform(X_test),y_test)))\n",
    "\n",
    "#R2 value for Polynomial regression\n",
    "print(\"R^2: {}\".format(r2_score(y_test,linreg.predict(poly_reg.fit_transform(X_test))))\n",
    "\n",
    "#Mean Squared Error\n",
    "mse = mean_squared_error(y_test,linreg.predict(poly_reg.fit_transform(X_test)))\n",
    "print(\"Mean Squared Error: {}\".format(mse))\n",
    "\n",
    "#Root Mean sqaured Error\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))\n",
    "'''\n",
    "\n",
    "\n",
    "#Without using split \n",
    "#Accuracy\n",
    "print(\"Accuracy: {}\".format(linreg.score(poly_reg.fit_transform(X_salinity),y_temp)))\n",
    "\n",
    "#R2 value for Polynomial regression\n",
    "print(\"R^2: {}\".format(r2_score(y_temp,linreg.predict(poly_reg.fit_transform(X_salinity)))))\n",
    "\n",
    "#Mean Squared Error\n",
    "mse = mean_squared_error(y_temp,linreg.predict(poly_reg.fit_transform(X_salinity)))\n",
    "print(\"Mean Squared Error: {}\".format(mse))\n",
    "\n",
    "#Root Mean Squared Error\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,9))\n",
    "\n",
    "#Using the train and test data created using train_test_split\n",
    "#x_grid = np.arange(min(X_train),max(X_train),0.1)\n",
    "#x_grid = x_grid.reshape(-1,1)\n",
    "#plt.scatter(x=X_train,y=y_train, s=65)\n",
    "#plt.plot(x_grid, linreg.predict(poly_reg.fit_transform(x_grid)),color='black',linewidth=1)\n",
    "##plt.plot(X_test, linreg.predict(poly_reg.fit_transform(X_test)),color='black',linewidth=0.5)\n",
    "\n",
    "#Without using split\n",
    "x_grid = np.arange(min(X_salinity),max(X_salinity),0.1)\n",
    "plt.scatter(x=X_salinity,y=y_temp, s=65)\n",
    "plt.plot(x_grid, linreg.predict(poly_reg.fit_transform(x_grid.reshape(-1, 1))),color='black',linewidth=1)\n",
    "##plt.plot(X_salinity, linreg.predict(poly_reg.fit_transform(X_salinity)),color='black',linewidth=0.5)\n",
    "\n",
    "plt.suptitle(\"Temperature vs Salinity\")\n",
    "plt.xlabel(\"Salinity\")\n",
    "plt.ylabel(\"Temperature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of data\n",
    "When taken 5000 records, and split into train and test 70% to 30% \n",
    "- linear regression R^2: 0.4255818269267334\n",
    "- polynomial R^2: 0.5995609258276697\n",
    "\n",
    "When taken 10000 records, and split into train and test 70% to 30% \n",
    "- linear regression R^2: 0.4197186103543863\n",
    "- polynomial R^2: 0.6019485385877807\n",
    "\n",
    "When taken 20000 records, and split into train and test 70% to 30% \n",
    "- linear regression R^2: 0.3903003205569573\n",
    "- polynomial R^2: 0.5011620106176469\n",
    "\n",
    "When taken 1000 records, and split into train and test 70% to 30% \n",
    "- linerar regression = R^2: 0.7025832868957473\n",
    "- polynomial accuracy = R^2: 0.8312527943505363\n",
    "\n",
    "When taken 814247 records and split into train and test 70% to 30% \n",
    "- linear regression = R^2: 0.2544309253184054\n",
    "When taken 814247 records and without splitting\n",
    "- polynomial accuracy =R^2: 0.38193235969379824\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
