{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Look up SMOTE oversampling\n",
    "\n",
    "https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html .\n",
    "\n",
    "  - a. Describe what it is in your own words in markdown.\n",
    "  - b. Use this technique with the diabetes dataset. Comment on the model performance compared to other methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is SMOTE Oversampling\n",
    "- SMOTE - Synthetic Minority Over-Sampling Technique\n",
    "- SMOTE is a oversampling technique to balance the dataset by making minority and majority classes ratio balanced.\n",
    "- SMOTE creates artificial/synthetic data/records using the nearest neighbor method. It creates data between the nearest neighbor.\n",
    "    - SMOTE works by selecting examples that are close in the feature space, drawing a line between the examples in the feature space and drawing a new sample at a point along that line.\n",
    "    - Specifically, a random example from the minority class is first chosen. Then k of the nearest neighbors for that example are found (typically k=5). A randomly selected neighbor is chosen and a synthetic example is created at a randomly selected point between the two examples in feature space.\n",
    "    - The approach creates new synthetic examples from the minority class that are relatively close in feature space to existing examples from the minority class.\n",
    "\n",
    "\n",
    "- In below example non-diabetic is 500 and diabetic is 268, there is a imbalance in the data set\n",
    "- non-diabetic is a majority class and diabetic is a minority class\n",
    "- SMOTE will create new artifical data between the neartest neighor of the data points present in the minority class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE on diabetes dataset\n",
    "\n",
    "- We have done logistic regression model without oversampling method and got recall of 0.84 and accuracy 0.72\n",
    "- Using SMOTE oversampling techniques following results are acchieved\n",
    "    - Comparing it with logistic regression without ovesampling, accuracy score went a little bit up from 0.72 to 0.74 but recall value dropped from 0.84 to 0.74."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df = pd.read_csv(\"../week_13/diabetes.csv\")\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True False  True  True  True  True]\n",
      "[1 1 1 2 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X2 = diabetes_df.drop([\"Outcome\"],axis=1)\n",
    "y2 = diabetes_df[\"Outcome\"]\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "#Initializing RFE model\n",
    "rfe = RFE(model, 7)\n",
    "\n",
    "#Transforming data using RFE\n",
    "X_rfe = rfe.fit_transform(X2,y2)  \n",
    "\n",
    "#Fitting the data to model\n",
    "model.fit(X_rfe,y2)\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'Insulin', 'BMI',\n",
      "       'DiabetesPedigreeFunction', 'Age'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "rfe_features = X2.columns[np.where(rfe.support_ == True)[0]]\n",
    "print(rfe_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df[rfe_features]\n",
    "y = diabetes_df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There is a imbalance in dataset\n",
    "diabetes_df['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state=42,stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_scaler = sc.fit_transform(X_train)\n",
    "X_test_scaler = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataset shape: Counter({0: 400, 1: 214})\n",
      "Resample dataset shape Counter({0: 400, 1: 400})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "sm = SMOTE(sampling_strategy=1.0,random_state=42)   # Find out best ratio to get optimum performance\n",
    "X_res, y_res = sm.fit_resample(X_train_scaler, y_train)\n",
    "print('original dataset shape:', Counter(y_train))\n",
    "print('Resample dataset shape', Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic regression\n",
    "lregmodel = LogisticRegression(random_state=42)\n",
    "lregmodel.fit(X_res,y_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.741111111111111"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate accuracy\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "y_pred = lregmodel.predict(X_test_scaler)\n",
    "balanced_accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[76, 24],\n",
       "       [15, 39]], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,plot_confusion_matrix,classification_report\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x199ca652d90>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(lregmodel,X_test_scaler,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.76      0.80       100\n",
      "           1       0.62      0.72      0.67        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.74      0.73       154\n",
      "weighted avg       0.76      0.75      0.75       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.82      0.75      0.70      0.79      0.73      0.53       100\n",
      "          1       0.60      0.70      0.75      0.65      0.73      0.53        54\n",
      "\n",
      "avg / total       0.75      0.73      0.72      0.74      0.73      0.53       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a list of preprocessing steps you should try when working to build a model. Work with your group to come up with the most comprehensive list you can.\n",
    " \n",
    " - Handling null values\n",
    "     - drop the features that has most null values,\n",
    "     - fill the  null values based on skew and central tendency - mean or median\n",
    " - feature engineering\n",
    "     - creating new columns from the columns that have combined values e.g date can be separated in day, month and year\n",
    " - feature selection \n",
    "     - using correlation matrix\n",
    "     - RFE\n",
    " - remove extreme outliers\n",
    "     - use box plot to detect outliers\n",
    " - Standardization/Normalization\n",
    "     - Using StandardScaler from sklearn\n",
    " - One hot encoding \n",
    "     - pandas getdummies\n",
    " - Categorical to numerical \n",
    "     - LabelEncoder\n",
    " - handling multicollinearity\n",
    " - dimentinality reduction\n",
    " - converting data types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  In class - warm up activity- Write a list comprehension that puts all the even values from 1-1000 in a list. Create a new list from that list that has only the values with an 8 in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98, 100, 102, 104, 106, 108, 110, 112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132, 134, 136, 138, 140, 142, 144, 146, 148, 150, 152, 154, 156, 158, 160, 162, 164, 166, 168, 170, 172, 174, 176, 178, 180, 182, 184, 186, 188, 190, 192, 194, 196, 198, 200, 202, 204, 206, 208, 210, 212, 214, 216, 218, 220, 222, 224, 226, 228, 230, 232, 234, 236, 238, 240, 242, 244, 246, 248, 250, 252, 254, 256, 258, 260, 262, 264, 266, 268, 270, 272, 274, 276, 278, 280, 282, 284, 286, 288, 290, 292, 294, 296, 298, 300, 302, 304, 306, 308, 310, 312, 314, 316, 318, 320, 322, 324, 326, 328, 330, 332, 334, 336, 338, 340, 342, 344, 346, 348, 350, 352, 354, 356, 358, 360, 362, 364, 366, 368, 370, 372, 374, 376, 378, 380, 382, 384, 386, 388, 390, 392, 394, 396, 398, 400, 402, 404, 406, 408, 410, 412, 414, 416, 418, 420, 422, 424, 426, 428, 430, 432, 434, 436, 438, 440, 442, 444, 446, 448, 450, 452, 454, 456, 458, 460, 462, 464, 466, 468, 470, 472, 474, 476, 478, 480, 482, 484, 486, 488, 490, 492, 494, 496, 498, 500, 502, 504, 506, 508, 510, 512, 514, 516, 518, 520, 522, 524, 526, 528, 530, 532, 534, 536, 538, 540, 542, 544, 546, 548, 550, 552, 554, 556, 558, 560, 562, 564, 566, 568, 570, 572, 574, 576, 578, 580, 582, 584, 586, 588, 590, 592, 594, 596, 598, 600, 602, 604, 606, 608, 610, 612, 614, 616, 618, 620, 622, 624, 626, 628, 630, 632, 634, 636, 638, 640, 642, 644, 646, 648, 650, 652, 654, 656, 658, 660, 662, 664, 666, 668, 670, 672, 674, 676, 678, 680, 682, 684, 686, 688, 690, 692, 694, 696, 698, 700, 702, 704, 706, 708, 710, 712, 714, 716, 718, 720, 722, 724, 726, 728, 730, 732, 734, 736, 738, 740, 742, 744, 746, 748, 750, 752, 754, 756, 758, 760, 762, 764, 766, 768, 770, 772, 774, 776, 778, 780, 782, 784, 786, 788, 790, 792, 794, 796, 798, 800, 802, 804, 806, 808, 810, 812, 814, 816, 818, 820, 822, 824, 826, 828, 830, 832, 834, 836, 838, 840, 842, 844, 846, 848, 850, 852, 854, 856, 858, 860, 862, 864, 866, 868, 870, 872, 874, 876, 878, 880, 882, 884, 886, 888, 890, 892, 894, 896, 898, 900, 902, 904, 906, 908, 910, 912, 914, 916, 918, 920, 922, 924, 926, 928, 930, 932, 934, 936, 938, 940, 942, 944, 946, 948, 950, 952, 954, 956, 958, 960, 962, 964, 966, 968, 970, 972, 974, 976, 978, 980, 982, 984, 986, 988, 990, 992, 994, 996, 998, 1000]\n",
      "[8, 18, 28, 38, 48, 58, 68, 78, 80, 82, 84, 86, 88, 98, 108, 118, 128, 138, 148, 158, 168, 178, 180, 182, 184, 186, 188, 198, 208, 218, 228, 238, 248, 258, 268, 278, 280, 282, 284, 286, 288, 298, 308, 318, 328, 338, 348, 358, 368, 378, 380, 382, 384, 386, 388, 398, 408, 418, 428, 438, 448, 458, 468, 478, 480, 482, 484, 486, 488, 498, 508, 518, 528, 538, 548, 558, 568, 578, 580, 582, 584, 586, 588, 598, 608, 618, 628, 638, 648, 658, 668, 678, 680, 682, 684, 686, 688, 698, 708, 718, 728, 738, 748, 758, 768, 778, 780, 782, 784, 786, 788, 798, 800, 802, 804, 806, 808, 810, 812, 814, 816, 818, 820, 822, 824, 826, 828, 830, 832, 834, 836, 838, 840, 842, 844, 846, 848, 850, 852, 854, 856, 858, 860, 862, 864, 866, 868, 870, 872, 874, 876, 878, 880, 882, 884, 886, 888, 890, 892, 894, 896, 898, 908, 918, 928, 938, 948, 958, 968, 978, 980, 982, 984, 986, 988, 998]\n"
     ]
    }
   ],
   "source": [
    "even_values = [x for x in range(1,1001) if x % 2 == 0]\n",
    "print(even_values)\n",
    "with_8 = [val for val in even_values if \"8\" in str(val) ]\n",
    "print(with_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
